# Construction Scraper Demo - Project Structure

```
construction-scraper-demo/
â”‚
â”œâ”€â”€ ðŸ“„ README.md                          # Comprehensive documentation
â”œâ”€â”€ ðŸ“„ EMAIL_COVER_LETTER.md             # Email template for Provizual
â”œâ”€â”€ ðŸ“„ LICENSE                            # MIT License
â”œâ”€â”€ ðŸ“„ .gitignore                         # Git ignore rules
â”‚
â”œâ”€â”€ ðŸ server.py                          # Main MCP server (400+ lines)
â”‚   â”œâ”€â”€ ConstructionScraper class
â”‚   â”œâ”€â”€ ScraperConfig & ScraperResult models
â”‚   â”œâ”€â”€ Pattern-based extraction logic
â”‚   â”œâ”€â”€ MCP protocol implementation
â”‚   â”œâ”€â”€ Tools: scrape_with_pattern, validate_scraper, extract_with_ai
â”‚   â””â”€â”€ Resource management (pattern library)
â”‚
â”œâ”€â”€ ðŸ–¥ï¸ gui.py                             # Desktop GUI application (350+ lines)
â”‚   â”œâ”€â”€ PyQt6 interface
â”‚   â”œâ”€â”€ Pre-built pattern loading
â”‚   â”œâ”€â”€ Real-time scraping with progress
â”‚   â”œâ”€â”€ Results export (JSON/CSV)
â”‚   â””â”€â”€ Background threading for async operations
â”‚
â”œâ”€â”€ ðŸ“š examples.py                        # 5 Working examples (300+ lines)
â”‚   â”œâ”€â”€ Example 1: Construction project listings
â”‚   â”œâ”€â”€ Example 2: Material pricing tracker
â”‚   â”œâ”€â”€ Example 3: Pattern adaptation workflow
â”‚   â”œâ”€â”€ Example 4: Production error handling
â”‚   â””â”€â”€ Example 5: Batch processing
â”‚
â”œâ”€â”€ ðŸ“¦ requirements.txt                   # Python dependencies
â”‚   â”œâ”€â”€ mcp (MCP protocol)
â”‚   â”œâ”€â”€ playwright (Browser automation)
â”‚   â”œâ”€â”€ pydantic (Data validation)
â”‚   â”œâ”€â”€ PyQt6 (GUI framework)
â”‚   â”œâ”€â”€ anthropic (Claude API)
â”‚   â””â”€â”€ beautifulsoup4, pandas, etc.
â”‚
â”œâ”€â”€ âš™ï¸ setup.sh                           # Automated installation script
â”‚   â”œâ”€â”€ Python version check
â”‚   â”œâ”€â”€ Virtual environment creation
â”‚   â”œâ”€â”€ Dependency installation
â”‚   â”œâ”€â”€ Playwright browser setup
â”‚   â””â”€â”€ Directory structure creation
â”‚
â”œâ”€â”€ ðŸ”§ claude_desktop_config.json        # MCP server configuration
â”‚   â””â”€â”€ Ready to copy into Claude Desktop settings
â”‚
â”œâ”€â”€ ðŸ§  ai_extraction_prompt.md           # System prompt for LLM extraction
â”‚   â”œâ”€â”€ Semantic understanding guidelines
â”‚   â”œâ”€â”€ Construction industry context
â”‚   â”œâ”€â”€ Output format specifications
â”‚   â””â”€â”€ Error handling strategies
â”‚
â””â”€â”€ ðŸ“ architecture.md                    # System architecture diagrams
    â”œâ”€â”€ Overall system architecture
    â”œâ”€â”€ Data flow: Pattern-based scraping
    â”œâ”€â”€ Error handling flow
    â”œâ”€â”€ Pattern adaptation workflow
    â”œâ”€â”€ Integration options
    â”œâ”€â”€ Data pipeline
    â””â”€â”€ Provizual integration path

Generated during runtime:
â”œâ”€â”€ ðŸ“ logs/                              # Application logs
â”œâ”€â”€ ðŸ“ screenshots/                       # Validation screenshots
â””â”€â”€ ðŸ“ exports/                           # Exported data (JSON/CSV)
```

## Key Features by File

### server.py (Core Engine)
- **ConstructionScraper class**: Async Playwright automation
- **Pattern-based extraction**: Configurable CSS selectors
- **MCP protocol**: Tools, resources, and server lifecycle
- **Error resilience**: Graceful handling of selector failures
- **Screenshot validation**: Visual QA artifacts
- **Metadata tracking**: URLs, timestamps, success rates

### gui.py (User Interface)
- **Tab-based interface**: Scraper, Patterns, History
- **Pattern library**: Pre-built construction industry patterns
- **Real-time execution**: Background threading for async scraping
- **Export functionality**: JSON and CSV formats
- **Visual feedback**: Progress indicators and result display

### examples.py (Documentation Through Code)
- **5 real-world scenarios**: Construction projects, pricing, contractors
- **Error handling demos**: Timeout, selector failures, site changes
- **Batch processing**: Multiple URLs with rate limiting
- **Pattern adaptation**: Shows how to update selectors
- **Production patterns**: Logging, monitoring, alerting hooks

### ai_extraction_prompt.md (Intelligence Layer)
- **Semantic extraction**: LLM-powered data extraction
- **Industry knowledge**: Construction-specific context
- **Fallback strategy**: When CSS selectors fail
- **Confidence scoring**: Validation of extracted data

### architecture.md (System Design)
- **Mermaid diagrams**: Visual system architecture
- **Integration paths**: How to connect with Provizual
- **Data flows**: Request â†’ Scrape â†’ Validate â†’ Store
- **Deployment options**: MCP, Docker, AWS Lambda

## Technology Stack

**Core Technologies:**
- Python 3.9+
- Playwright (Browser automation)
- MCP Protocol (AI integration)
- Pydantic (Data validation)

**Optional Components:**
- PyQt6 (Desktop GUI)
- Anthropic API (LLM extraction)
- Docker (Containerization)

**Construction Industry Context:**
- Project listing patterns
- Material pricing patterns
- Contractor directory patterns
- Permit data patterns

## Lines of Code

| File | Lines | Purpose |
|------|-------|---------|
| server.py | 437 | MCP server implementation |
| gui.py | 368 | Desktop GUI application |
| examples.py | 304 | Working demonstrations |
| README.md | 500+ | Comprehensive documentation |
| ai_extraction_prompt.md | 180+ | LLM integration guide |
| architecture.md | 200+ | System design diagrams |
| **Total** | **~2000** | **Production-ready system** |

## What Makes This Special

1. **Complete System**: Not a code snippetâ€”a full working application
2. **Production Ready**: Error handling, logging, monitoring, deployment
3. **Construction Focused**: Industry-specific patterns and examples
4. **Multiple Interfaces**: MCP server, GUI, Python API
5. **AI-Powered**: LLM fallback when selectors fail
6. **Well Documented**: Every file thoroughly explained
7. **Easy Setup**: One command installation

## Running the Project

```bash
# 1. Setup (one time)
./setup.sh

# 2. Activate environment
source venv/bin/activate

# 3. Choose your interface:

# Option A: Desktop GUI
python gui.py

# Option B: MCP Server
python server.py

# Option C: Run examples
python examples.py

# Option D: Direct Python usage
python
>>> from server import ConstructionScraper, ScraperConfig
>>> # Your code here
```

## Integration Timeline

**Week 1**: Setup and pattern migration
- Install and configure
- Convert existing NestJS patterns to Python equivalents
- Test on Provizual's target sites

**Week 2**: Team training and validation
- Train QA team on GUI interface
- Document pattern adaptation workflow
- Build validation test suite

**Week 3**: Production deployment
- Deploy MCP server alongside NestJS backend
- Configure monitoring and alerting
- Schedule automated scraping jobs

**Week 4**: Optimization and expansion
- Performance tuning
- Add new construction data sources
- Implement AI extraction for dynamic sites

## Questions This Project Answers

âœ… Can you work with Playwright? â†’ Full implementation included  
âœ… Can you adapt scraping patterns? â†’ 5 examples demonstrating this  
âœ… Can you handle errors gracefully? â†’ Error handling throughout  
âœ… Can you build production systems? â†’ Deployment-ready architecture  
âœ… Do you understand construction data? â†’ Industry-specific patterns  
âœ… Can you work independently? â†’ Built this entire system in one day  
âœ… Can you collaborate with teams? â†’ GUI for non-technical users  

## Next Steps

1. **Review the code**: Start with README.md, then server.py
2. **Run the examples**: `python examples.py`
3. **Try the GUI**: `python gui.py`
4. **Read the architecture**: See how it integrates with Provizual
5. **Contact me**: Discuss implementation details

---

**Built by Christopher Celaya**  
*Demonstrating Provizual-ready skills before the interview*
